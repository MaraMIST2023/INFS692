optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#compile
model %>% compile(
loss = "catrgorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
history <- model %>%
fit(
x = X,
y = Y,
epochs = 10,
batch_size = 128,
validation_split = 0.15,
verbose = FALSE
)
knitr::opts_chunk$set(echo = TRUE)
library(tensorflow)
library(keras)
library(dplyr)
#Load the dataset
radData <- read.csv("radiomics_completedata.csv")
str(radData)
#check first entries
head(radData)
#null and missing values
na.omit(radData)
#normalize
rad <- radData %>% mutate_if(is.ordered, factor, ordered = FALSE)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
#checking size...
summary(rad_train)
summary(rad_test)
#Identify features
Y <- "Failure.binary"
X <- setdiff(names(rad_train), Y)
#Convert to categorical
#Y <- rad$Failure.binary
#Y <- to_categorical(Y, 180)
#Convert to matrix
#rad_mat <- as.matrix(rad)
#class(rad_mat)
#Create model
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "sigmoid", input_shape = ncol(X)) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 128, activation = "sigmoid") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 128, activation = "sigmoid") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 64, activation = "sigmoid") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 64, activation = "sigmoid") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 2, activation = "softmax")
#backpropagate
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#compile
model %>% compile(
loss = "catrgorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
history <- model %>%
fit(
x = X,
y = Y,
epochs = 10,
batch_size = 128,
validation_split = 0.15,
verbose = FALSE
)
#Create model
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = "sigmoid", input_shape = ncol(X)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = "sigmoid") %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = "sigmoid") %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 64, activation = "sigmoid") %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 64, activation = "sigmoid") %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 2, activation = "softmax")
#backpropagate
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#compile
model %>% compile(
loss = "catrgorical_crossentropy",
optimizer = optimizer_adam(),
metrics = c("accuracy")
)
history <- model %>%
fit(
x = X,
y = Y,
epochs = 10,
batch_size = 128,
validation_split = 0.15,
verbose = FALSE
)
#Identify features
Y <- "Failure.binary"
X <- setdiff(names(rad_train), Y)
#Convert to categorical
Y <- rad$Failure.binary
Y <- to_categorical(Y, 180)
#Convert to matrix
#rad_mat <- as.matrix(rad)
#class(rad_mat)
history <- model %>%
fit(
x = X,
y = Y,
epochs = 10,
batch_size = 128,
validation_split = 0.15,
verbose = FALSE
)
#checking size...
str(rad_train)
str(rad_test)
#checking size...
str(rad_train)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(caret)
library(rsample)
library(recipes)
library(dplyr)
library(ggplot2)
library(vip)
#Load the dataset
radData <- read.csv("radiomics_completedata.csv")
str(radData)
#check first entries
head(radData)
#null and missing values
na.omit(radData)
#normalize
rad <- radData %>% mutate_if(is.ordered, factor, ordered = FALSE)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
blueprint <- recipe(Failure.binary ~ ., data = rad_train) %>%
step_other(all_nominal(), threshold = 0.005)
h2o.init()
train.h2o <- prep(blueprint, training = rad_train, retain = TRUE) %>%
juice() %>%
as.h2o()
test.h2o <- prep(blueprint, training = rad_train) %>%
bake(new_data = rad_test) %>%
as.h2o()
Y <- "Failure.binary"
X <- setdiff(names(rad_train), Y)
#training matrices
#X <- model.matrix(Failure.binary ~ ., rad_train)[, -1]
#log transformation
#Y <- log(rad_train$Failure.binary)
#lasso <- cv.glmnet(
#  x = X,
#  y = Y,
#  alpha = 1
#)
set.seed(24)
model1 <- train(
Failure.binary ~ .,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
#Correlation
cor(x, y,  method = "pearson", use = "complete.obs")
#Correlation
cor(X, Y,  method = "pearson", use = "complete.obs")
XN <- as.numeric(X)
#Correlation
cor(XN, Y,  method = "pearson", use = "complete.obs")
#Correlation
cor(XN, YN,  method = "pearson", use = "complete.obs")
YN <- as.numeric(Y)
#Correlation
cor(XN, YN,  method = "pearson", use = "complete.obs")
# correlation for all variables
round(cor(rad),
digits = 2 # rounded to 2 decimals
)
# correlation for all variables
cor(rad),
# correlation for all variables
cor(rad)
# correlation for all variables
round(cor(XN),
digits = 2 # rounded to 2 decimals
)
# correlation for all variables
round(cor(XN, YN),
digits = 2 # rounded to 2 decimals
)
cor(rad)
#check first entries
head(radData)
cor(radData)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(caret)
library(rsample)
library(recipes)
library(dplyr)
library(ggplot2)
library(vip)
#Load the dataset
radData <- read.csv("radiomics_completedata.csv")
str(radData)
#check first entries
head(radData)
#null and missing values
na.omit(radData)
#normalize
rad <- radData %>% mutate_if(is.ordered, factor, ordered = FALSE)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
blueprint <- recipe(Failure.binary ~ ., data = rad_train) %>%
step_other(all_nominal(), threshold = 0.005)
h2o.init()
train.h2o <- prep(blueprint, training = rad_train, retain = TRUE) %>%
juice() %>%
as.h2o()
test.h2o <- prep(blueprint, training = rad_train) %>%
bake(new_data = rad_test) %>%
as.h2o()
Y <- "Failure.binary"
YN <- as.numeric(Y)
X <- setdiff(names(rad_train), Y)
XN <- as.numeric(X)
#Correlation
cor(XN, YN,  method = "pearson", use = "complete.obs")
set.seed(24)
model1 <- train(
Failure.binary ~ .,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
model1 <- train(
rad$Failure.binary ~ .,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
View(rad)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
blueprint <- recipe(Failure.binary ~ ., data = rad_train) %>%
step_other(all_nominal(), threshold = 0.005)
Y <- "Failure.binary"
YN <- as.numeric(Y)
X <- setdiff(names(rad_train), Y)
XN <- as.numeric(X)
#Correlation
#cor(XN, YN,  method = "pearson", use = "complete.obs")
#training matrices
#X <- model.matrix(Failure.binary ~ ., rad_train)[, -1]
#log transformation
#Y <- log(rad_train$Failure.binary)
#lasso <- cv.glmnet(
#  x = X,
#  y = Y,
#  alpha = 1
#)
set.seed(24)
model1 <- train(
rad$Failure.binary ~ .,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
#train and validate glm
rad_glm <- h2o.glm(
x = X, y = Y, training_frame = train.h2o, alpha = 0.1,
remove_collinear_columns = TRUE, nfolds = 10, fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE, seed = 24
)
library(ROCR)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
Y <- "Failure.binary"
YN <- as.numeric(Y)
X <- setdiff(names(rad_train), Y)
XN <- as.numeric(X)
#Correlation
#cor(XN, YN,  method = "pearson", use = "complete.obs")
#training matrices
#X <- model.matrix(Failure.binary ~ ., rad_train)[, -1]
#log transformation
#Y <- log(rad_train$Failure.binary)
#lasso <- cv.glmnet(
#  x = X,
#  y = Y,
#  alpha = 1
#)
set.seed(24)
model1 <- train(
rad$Failure.binary ~ .,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
set.seed(24)
model1 <- train(
Failure.binary ~ .,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
model1 <- train(
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
model1 <- train(
rad ~ Failure.binary,
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
model1 <- train(
rad ~ "Failure.binary",
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
library(glmnet)
library(caret)
library(rsample)
library(ROCR)
library(dplyr)
library(ggplot2)
library(vip)
#Load the dataset
radData <- read.csv("radiomics_completedata.csv")
str(radData)
#check first entries
head(radData)
#null and missing values
na.omit(radData)
#normalize
rad <- radData %>% mutate_if(is.ordered, factor, ordered = FALSE)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
Y <- "Failure.binary"
YN <- as.numeric(Y)
X <- setdiff(names(rad_train), Y)
XN <- as.numeric(X)
#Correlation
#cor(XN, YN,  method = "pearson", use = "complete.obs")
#training matrices
#X <- model.matrix(Failure.binary ~ ., rad_train)[, -1]
#log transformation
#Y <- log(rad_train$Failure.binary)
#lasso <- cv.glmnet(
#  x = X,
#  y = Y,
#  alpha = 1
#)
set.seed(24)
model1 <- train(
rad ~ "Failure.binary",
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
library(randomForest)
library(glmnet)
library(caret)
library(ROCR)
library(dplyr)
library(ggplot2)
library(vip)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(caret)
library(ROCR)
library(dplyr)
library(ggplot2)
library(vip)
#Load the dataset
radData <- read.csv("radiomics_completedata.csv")
str(radData)
#check first entries
head(radData)
#null and missing values
na.omit(radData)
#normalize
#rad <- radData %>% mutate_if(is.ordered, factor, ordered = FALSE)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
Y <- "Failure.binary"
YN <- as.numeric(Y)
X <- setdiff(names(rad_train), Y)
XN <- as.numeric(X)
#Correlation
#cor(XN, YN,  method = "pearson", use = "complete.obs")
#training matrices
#X <- model.matrix(Failure.binary ~ ., rad_train)[, -1]
#log transformation
#Y <- log(rad_train$Failure.binary)
#lasso <- cv.glmnet(
#  x = X,
#  y = Y,
#  alpha = 1
#)
set.seed(24)
model1 <- train(
rad ~ "Failure.binary",
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
#Load the dataset
radData <- read.csv("radiomics_completedata.csv")
str(radData)
#check first entries
head(radData)
#null and missing values
na.omit(radData)
#normalize
rad <- radData %>% mutate_if(is.ordered, factor, ordered = FALSE)
#Split data into training (80%) and testing (20%)
set.seed(24)
rad_split <- initial_split(rad, prop = 0.8, strata = "Failure.binary")
rad_train <- training(rad_split)
rad_test <- testing(rad_split)
Y <- "Failure.binary"
YN <- as.numeric(Y)
X <- setdiff(names(rad_train), Y)
XN <- as.numeric(X)
#Correlation
#cor(XN, YN,  method = "pearson", use = "complete.obs")
#training matrices
#X <- model.matrix(Failure.binary ~ ., rad_train)[, -1]
#log transformation
#Y <- log(rad_train$Failure.binary)
#lasso <- cv.glmnet(
#  x = X,
#  y = Y,
#  alpha = 1
#)
testData <- rad[-trainIndex, ]
set.seed(123)
trainIndex <- createDataPartition(rad$Failure.binary, p = 0.8, list = FALSE)
trainData <- rad[trainIndex, ]
testData <- rad[-trainIndex, ]
set.seed(24)
model1 <- train(
rad ~ "Failure.binary",
data = rad_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
lrModel <- train(Species ~ ., data = trainData, method = "glm", family = "binomial")
lrModel <- train(Failure.binary ~ ., data = trainData, method = "glm", family = "binomial")
library(keras)
set.seed(123)
trainIndex <- createDataPartition(rad$Failure.binary, p = 0.8, list = FALSE)
trainData <- rad[trainIndex, ]
testData <- rad[-trainIndex, ]
lrModel <- train(Failure.binary ~ ., data = trainData, method = "glm", family = "binomial")
